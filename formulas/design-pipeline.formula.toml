description = "Multi-phase design workflow with parallel review convoy. Progresses from research through drafting, multi-angle review, and human-gated synthesis. Dispatch with: gt sling <bead> <rig> --no-merge"
formula = "design-pipeline"
type = "workflow"
version = 1

# TODO: compose.expand with document-review convoy when bd supports convoy type
# [compose]
# [[compose.expand]]
# target = "dispatch-reviews"
# with = "document-review"

[[steps]]
id = "research"
title = "Research {{topic}}"
description = """Investigate the problem space per /seed-research.

Setup: Create a branch named after the parent bead (git checkout -b <bead-id>). Design artifacts go in docs/design/<bead-id>-<descriptor>.md.

Survey internal context (code, docs, beads, prior art), validate assumptions, research externally as needed. Produce a structured findings document committed to the branch. Do NOT propose solutions — map the territory."""
checklist = "research-complete"

[[steps]]
id = "draft"
title = "Draft design for {{topic}}"
needs = ["research"]
description = "Synthesize research into a design document. Propose 2-4 options with tradeoffs. Include a recommendation with justification. Address open questions from research where possible; flag remaining unknowns. Commit the design doc to the branch and update the bead design field: bd update <issue> --design \"<summary>\""
checklist = "design-drafted"

[[steps]]
id = "dispatch-reviews"
title = "Review {{topic}} design via convoy"
needs = ["draft"]
description = """Parallel multi-lens document review. Expanded by compose.expand with document-review convoy formula.

Minimum lenses: feasibility, adversarial, completeness. Additional lenses based on topic scope.
Each reviewer applies /seed-document-review with their assigned lens. Convoy synthesis produces
a unified review with BLOCK/CONCERN/NOTE findings, gate assessment, and revised recommendation.

All reviews and synthesis committed to the branch."""
checklist = "review-convoy-complete"

[[steps]]
id = "human-gate"
title = "Human review of {{topic}} design"
needs = ["dispatch-reviews"]
description = "HUMAN GATE. Present the synthesis to the human. Include: the revised recommendation, key conflicts that need resolution, and any open questions. The human may approve, request revisions (cycle back to draft), or redirect. Mail the mayor with DESIGN REVIEW summary."
checklist = "human-gate-passed"
gate = { type = "human" }

[[steps]]
id = "finalize"
title = "Finalize {{topic}} design"
needs = ["human-gate"]
description = """Apply human feedback. If approved: update design doc as final, close review child beads, update parent bead design field with final summary. If revisions requested: update the draft, optionally dispatch another review convoy, and cycle back through human-gate.

Deliverables:
- Final design document on branch
- Implementation beads decomposed from the design (if human approves proceeding)
- Bead design field updated with final summary"""
checklist = "design-finalized"

[[steps]]
id = "retro"
title = "Retrospective: {{topic}} design pipeline"
needs = ["finalize"]
description = """Analyze this workflow execution and produce a retro document. Review:

1. Process compliance — did each step follow its skill? Were any steps rushed or skipped?
2. Artifact quality — was the research thorough? Was the design well-reasoned? Were reviews substantive or rubber-stamps?
3. Review convoy effectiveness — did the lenses produce distinct findings? Were there redundant or missing angles?
4. Rationalizations observed — any moments where the agent (or reviewers) cut corners, skipped checks, or made excuses? Capture exact rationalizations for skill improvement.
5. Cycle efficiency — what could have been parallelized? Where did the human wait unnecessarily? Where did agents wait unnecessarily?
6. Skill gaps — did any step lack a skill that would have helped? Were existing skills adequate?

⚠️ WARNING: This retro step produces findings. It does NOT authorize acting on them.
All findings MUST be presented at the retro-human gate before implementation.
Do not skip ahead to implementing 'obvious' fixes — that is the agent deciding
which of its own oversight steps to skip, which is the exact failure mode human
gates exist to prevent. See retro-human step.

File ks beads for actionable findings. Link to existing ks issues if the pattern is already tracked.
For each new rationalization observed, note which skill's rationalization table should be updated.

Commit retro document to the branch."""
checklist = "retro-complete"

[[steps]]
id = "retro-human"
title = "Human retro checkpoint for {{topic}}"
needs = ["retro"]
description = """HUMAN GATE. Present the retro findings to the human. Include:

1. Summary of what worked and what didn't in this pipeline run
2. Proposed keeper improvements (skill updates, formula changes, new skills needed)
3. New rationalizations to add to skill tables
4. Any beads filed and their priority

The human decides which improvements to pursue. Approved improvements become keeper beads dispatched through standard-feature or the skill-improvement lifecycle (red test → draft → green test → merge).

⚠️ KNOWN RATIONALIZATION: 'The fixes are small and obvious, no need for human review.'
This gate exists precisely because agents cannot be trusted to judge which oversight
steps are safe to skip. During ks-jiqsy dogfood, the crew executed the AI retro then
immediately implemented findings without presenting them here. The implicit reasoning
was that the changes were too minor to warrant human review. This is the canonical
example of the pattern this gate prevents: the agent deciding which of its own oversight
steps to skip. No matter how small or obvious the findings seem, they MUST be presented
here before any action is taken."""
checklist = "human-gate-passed"
gate = { type = "human" }

[vars]
[vars.topic]
description = "The design topic or problem to investigate"
required = true
